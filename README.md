# 💬 تحلیل احساسات نظرات کاربران دیجی‌کالا (فارسی)

پروژه‌ای برای تحلیل احساسات نظرات کاربران فارسی دیجی‌کالا با استفاده از تکنیک‌های پردازش زبان طبیعی (NLP) و یادگیری ماشین. هدف این پروژه دسته‌بندی نظرات به سه کلاس احساسی (منفی، خنثی، مثبت) و تحلیل و بهبود دقت مدل‌ها در مواجهه با داده‌های نامتوازن است.

---

## 🎯 هدف پروژه

- تحلیل و پیش‌بینی احساسات نظرات کاربران به سه دسته‌بندی:
  - ۱ = منفی
  - ۲ = خنثی
  - ۳ = مثبت
- حل مشکل عدم‌تعادل داده‌ها (class imbalance) با استفاده از تکنیک‌هایی مانند SMOTE و انتخاب مدل‌های مناسب.
- بهبود دقت مدل‌ها و ارزیابی نتایج با معیارهای مختلف.

---

## 🧰 ابزارها و تکنولوژی‌ها

- زبان برنامه‌نویسی: Python
- محیط اجرا: Google Colab
- کتابخانه‌ها:
  - پردازش زبان طبیعی: [hazm](https://github.com/sobhe/hazm)
  - بردارسازی متن: `TfidfVectorizer`
  - مدل‌ها:
    - **Support Vector Machine (SVM)**
    - Naive Bayes
    - Logistic Regression
  - تکنیک‌های تقویت داده: **SMOTE**
  - مصورسازی: Matplotlib, Seaborn
- ارزیابی مدل‌ها: DTree, Precision, Recall, F1-Score, Confusion Matrix

---

## 🔬 مراحل انجام پروژه

1. **پیش‌پردازش داده‌های فارسی**:
   - نرمال‌سازی، توکن‌سازی و Lemmatization با hazm.
   - حذف مقادیر ناقص و صفرهای مصنوعی.

2. **بردارسازی متن با TF-IDF**:
   - استفاده از n-gram برای پوشش ترکیب واژگان مهم.

3. **آموزش و ارزیابی مدل‌ها**:
   - بررسی و مقایسه مدل‌های مختلف: **Naive Bayes**, **Logistic Regression**, و **SVM**.
   - استفاده از **SMOTE** برای حل مشکل عدم‌تعادل داده‌ها.

4. **ارزیابی عملکرد**:
   - استفاده از معیارهای دقت، Recall و F1 برای مقایسه مدل‌ها.
   - بررسی confusion matrix برای تحلیل رفتار مدل در هر کلاس.

---

## 📊 نتایج مدل نهایی (SVM)

| کلاس احساس | Precision | Recall | F1-score |
|------------|-----------|--------|----------|
| منفی (1)   | 1.00      | 0.92   | 0.96     |
| خنثی (2)   | 0.75      | 0.99   | 0.85     |
| مثبت (3)   | 0.88      | 0.99   | 0.93     |

📌 **دقت نهایی (Accuracy): 93.7%**  
📌 **Macro Avg F1: 91%**

### توضیح:
مدل SVM توانست عملکرد بسیار خوبی در هر سه کلاس احساسات نشان دهد. خصوصاً در کلاس‌های اقلیت (۲ و ۳)، که مدل‌های قبلی مشکلات جدی داشتند.

---

## 🧑‍💻 مقایسه مدل‌ها

| مدل | دقت (Accuracy) | F1 متوسط کلاس‌ها | نکات |
|-----|-----------------|------------------|------|
| **Naive Bayes** | 74% | بسیار پایین برای کلاس ۲ و ۳ | مشکل در class imbalance |
| **SMOTE + Naive Bayes** | 82% | بهبود در کلاس ۲ | دقت پایین‌تر از SVM |
| **Logistic Regression (Balanced)** | 89.9% | خوب | دقت کمتر از SVM |
| **SVM** | **93.7%** | **عالی در همه کلاس‌ها** | بهترین انتخاب نهایی |

---

## 📈 مصورسازی‌ها
- **Confusion Matrix** رنگی برای ارزیابی مدل در هر کلاس.
- **Precision/Recall** بار چارت برای بررسی تعادل در دقت و فراخوانی هر کلاس.
- **WordCloud** برای مشاهده کلمات پرتکرار در هر احساس.

---

## 🚀 مسیرهای بعدی توسعه

- استفاده از مدل‌های **ParsBERT** یا **Multilingual BERT** برای بهبود درک معنایی و تحلیل احساسات.
- طراحی و توسعه **API** برای استفاده عملی از مدل در اپلیکیشن‌ها یا وب‌سایت‌ها.
- استفاده از تکنیک‌های **fine-tuning** با داده‌های بیشتر و منابع غنی‌تر فارسی.

---

## 🧑‍💻 توسعه‌دهنده

📧 ایمیل: muhammadbeyzaei.code@gmail.com

## 📁 ساختار پروژه

